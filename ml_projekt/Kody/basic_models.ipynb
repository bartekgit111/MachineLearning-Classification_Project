{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WstÄ™p do Uczenia Maszynowego - Projekt\n",
    "##### Bartosz Chudek 327426"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from preprocessors import preprocessor_select, preprocessor_PCA\n",
    "from model_tuner import model_tuner\n",
    "from param_grids import param_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Podstawowe modele\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model drzewa decyzyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "8400 fits failed out of a total of 42000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1024, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 252, in _fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2966, in validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_X_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by DecisionTreeClassifier.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1024, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 252, in _fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2966, in validate_data\n",
      "    X = check_array(X, input_name=\"X\", **check_X_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by DecisionTreeClassifier.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.50112176 ... 0.71029403 0.74327519 0.70051295]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"tree_select\"] = model_tuner(DecisionTreeClassifier(),preprocessor_select(),param_grids[\"params_tree_select\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"tree_PCA\"] = model_tuner(DecisionTreeClassifier(),preprocessor_PCA(),param_grids[\"params_tree_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modele regresji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "56 fits failed out of a total of 280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by LogisticRegression.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by LogisticRegression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.60470017 0.57050776 0.57980309 0.58306026\n",
      " 0.58259295 0.58189267 0.58256652 0.58256652        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58306026 0.58339552 0.58116596\n",
      " 0.58116596 0.58256652        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58127818 0.58327322 0.58119239 0.58119239 0.58189267\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58248883\n",
      " 0.58189267 0.58119239 0.58119239 0.58189267]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"glm_select\"] = model_tuner(LogisticRegression(penalty=None, max_iter=10000),preprocessor_select(),param_grids[\"params_glm_select\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"glm_PCA\"] = model_tuner(LogisticRegression(penalty=None, max_iter=10000),preprocessor_PCA(),param_grids[\"params_glm_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "700 fits failed out of a total of 3500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by LogisticRegression.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by LogisticRegression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.59873622 0.57347636 0.5824417  0.58709853\n",
      " 0.57879636 0.58680913 0.58631662 0.58841746        nan        nan\n",
      " 0.6068525  0.58158744 0.58896183 0.58606733 0.58220532 0.59142207\n",
      " 0.59129554 0.59135807        nan        nan 0.59873622 0.57347636\n",
      " 0.5824417  0.58709853 0.57879636 0.58680913 0.58631662 0.58841746\n",
      "        nan        nan 0.59878615 0.57347636 0.5824417  0.58709853\n",
      " 0.57879636 0.58680913 0.58631662 0.58841746        nan        nan\n",
      " 0.59682296 0.57347636 0.5824417  0.58709853 0.57879636 0.58680913\n",
      " 0.58631662 0.58841746        nan        nan 0.60535292 0.58039275\n",
      " 0.58294935 0.58642854 0.58744652 0.58580236 0.58654447 0.58520644\n",
      "        nan        nan 0.60426945 0.57826394 0.58664846 0.58954802\n",
      " 0.58535283 0.58761538 0.58483201 0.58221847        nan        nan\n",
      " 0.60535292 0.58039275 0.58294935 0.58838074 0.58744652 0.58580236\n",
      " 0.58590672 0.58520644        nan        nan 0.60544787 0.58039275\n",
      " 0.58294935 0.58703904 0.58744652 0.58580236 0.58654447 0.58520644\n",
      "        nan        nan 0.60535292 0.58039275 0.58294935 0.58838074\n",
      " 0.58744652 0.58580236 0.58654447 0.58520644        nan        nan\n",
      " 0.60485898 0.57124944 0.58213831 0.585191   0.58876877 0.58965141\n",
      " 0.58969049 0.58969049        nan        nan 0.60382907 0.57097126\n",
      " 0.58136772 0.58526941 0.58714073 0.59000732 0.59077082 0.58937026\n",
      "        nan        nan 0.60485898 0.5718872  0.58339895 0.58566528\n",
      " 0.58876877 0.58965141 0.58969049 0.58969049        nan        nan\n",
      " 0.60485898 0.5718872  0.58283859 0.585191   0.58876877 0.58965141\n",
      " 0.58969049 0.58969049        nan        nan 0.60485898 0.5724977\n",
      " 0.58283859 0.58566528 0.58876877 0.58965141 0.58969049 0.58969049\n",
      "        nan        nan 0.60543421 0.57133466 0.58192313 0.5803555\n",
      " 0.58309652 0.58233647 0.58233647 0.58233647        nan        nan\n",
      " 0.60600564 0.57197241 0.58185978 0.57961913 0.58309652 0.58294697\n",
      " 0.58233647 0.58233647        nan        nan 0.60543421 0.57197241\n",
      " 0.58192313 0.5803555  0.58309652 0.58233647 0.58233647 0.58233647\n",
      "        nan        nan 0.60543421 0.57197241 0.58192313 0.5803555\n",
      " 0.58309652 0.58233647 0.58233647 0.58233647        nan        nan\n",
      " 0.60543421 0.57197241 0.58192313 0.5803555  0.58309652 0.58233647\n",
      " 0.58233647 0.58233647        nan        nan 0.60463164 0.56991288\n",
      " 0.5792051  0.57830961 0.5863613  0.58262807 0.58135256 0.58135256\n",
      "        nan        nan 0.60463164 0.56991288 0.5804261  0.57896492\n",
      " 0.5849534  0.5826605  0.583271   0.58202274        nan        nan\n",
      " 0.60463164 0.56930238 0.5792051  0.57896492 0.58555873 0.58138498\n",
      " 0.58074723 0.58074723        nan        nan 0.60463164 0.56930238\n",
      " 0.5792051  0.57896492 0.5849534  0.58202274 0.58138498 0.58138498\n",
      "        nan        nan 0.60463164 0.56991288 0.5792051  0.57896492\n",
      " 0.5849534  0.58202274 0.58138498 0.58138498        nan        nan\n",
      " 0.60402632 0.57114552 0.57980309 0.58749275 0.58452204 0.5826811\n",
      " 0.5826811  0.5826811         nan        nan 0.60463164 0.57057409\n",
      " 0.57980309 0.58809807 0.58452204 0.5826811  0.5826811  0.5826811\n",
      "        nan        nan 0.60463164 0.57057409 0.57980309 0.58817302\n",
      " 0.58452204 0.5826811  0.5826811  0.5826811         nan        nan\n",
      " 0.60463164 0.57057409 0.57980309 0.58817302 0.58452204 0.5826811\n",
      " 0.5826811  0.5826811         nan        nan 0.60463164 0.57057409\n",
      " 0.57980309 0.58817302 0.58452204 0.5826811  0.5826811  0.5826811\n",
      "        nan        nan 0.60402632 0.57114552 0.57914778 0.58549234\n",
      " 0.58524243 0.58589493 0.58655024 0.5852122         nan        nan\n",
      " 0.60402632 0.57057409 0.57914778 0.58596662 0.58524243 0.58655024\n",
      " 0.58655024 0.58591248        nan        nan 0.60402632 0.57057409\n",
      " 0.57914778 0.58549234 0.58581386 0.58525717 0.58591248 0.58517611\n",
      "        nan        nan 0.60402632 0.57057409 0.57914778 0.58596662\n",
      " 0.58524243 0.58591248 0.58655024 0.58591248        nan        nan\n",
      " 0.60402632 0.57057409 0.57914778 0.58596662 0.58524243 0.58591248\n",
      " 0.58591248 0.58591248        nan        nan 0.60470017 0.57050776\n",
      " 0.57980309 0.58454324 0.5834139  0.58331161 0.58331161 0.58331161\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58454324\n",
      " 0.5834139  0.58331161 0.58331161 0.58331161        nan        nan\n",
      " 0.60402632 0.56993633 0.57914778 0.58333258 0.5834139  0.58331161\n",
      " 0.58331161 0.58257523        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58454324 0.5834139  0.58331161 0.58331161 0.58331161\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58406896\n",
      " 0.5834139  0.58331161 0.58331161 0.58331161        nan        nan\n",
      " 0.60470017 0.57050776 0.57980309 0.58127818 0.58336909 0.5826563\n",
      " 0.5826563  0.5826563         nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58127818 0.58269524 0.58195602 0.58256652 0.58256652\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58127818\n",
      " 0.58336909 0.58125574 0.58125574 0.58195602        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58127818 0.58336909 0.58195602\n",
      " 0.58256652 0.58256652        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58127818 0.58336909 0.58195602 0.58195602 0.58195602\n",
      "        nan        nan 0.60470017 0.57050776 0.57980309 0.58127818\n",
      " 0.58339552 0.58256652 0.58256652 0.58256652        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58127818 0.58269524 0.58256652\n",
      " 0.58256652 0.58256652        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.5818835  0.58269524 0.58116596 0.58186624 0.58256652\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58248883\n",
      " 0.58269524 0.58256652 0.58256652 0.58256652        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58127818 0.58269524 0.58256652\n",
      " 0.58256652 0.58256652]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"glm_l2_select\"] = model_tuner(LogisticRegression(penalty=\"l2\", max_iter=10000),preprocessor_select(),param_grids[\"params_glm_l2_select\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"glm_l2_PCA\"] = model_tuner(LogisticRegression(penalty=\"l2\", max_iter=10000),preprocessor_PCA(),param_grids[\"params_glm_l2_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "280 fits failed out of a total of 1400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by LogisticRegression.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by LogisticRegression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.61178916 0.61178916 0.61178916 0.61178916 0.61178916 0.61178916\n",
      " 0.61178916 0.61178916        nan        nan 0.61047248 0.61047248\n",
      " 0.61047248 0.61047248 0.61047248 0.61047248 0.61047248 0.61047248\n",
      "        nan        nan 0.60506502 0.60249727 0.60249727 0.60249727\n",
      " 0.60249727 0.60249727 0.60249727 0.60249727        nan        nan\n",
      " 0.60419347 0.59952    0.59952    0.59952    0.59952    0.59952\n",
      " 0.59881972 0.59952           nan        nan 0.60413402 0.57475512\n",
      " 0.58470283 0.58738775 0.58470283 0.58470283 0.58470283 0.58470283\n",
      "        nan        nan 0.60620302 0.57850796 0.58329094 0.58258182\n",
      " 0.5839287  0.58329094 0.58329094 0.58329094        nan        nan\n",
      " 0.60481225 0.57485769 0.58384709 0.58054227 0.58054227 0.57993177\n",
      " 0.58054227 0.58054227        nan        nan 0.60470017 0.57502264\n",
      " 0.58200985 0.58066815 0.58009672 0.58066815 0.58066815 0.58066815\n",
      "        nan        nan 0.6052694  0.57117941 0.57792091 0.58513316\n",
      " 0.58319147 0.58319147 0.58319147 0.58319147        nan        nan\n",
      " 0.60470017 0.57057409 0.57872347 0.58392251 0.58319147 0.58319147\n",
      " 0.58319147 0.58319147        nan        nan 0.60402632 0.56993633\n",
      " 0.57849247 0.5826323  0.58405165 0.58337794 0.58337794 0.58337794\n",
      "        nan        nan 0.60402632 0.56993633 0.57849247 0.58271337\n",
      " 0.58405165 0.58337794 0.58337794 0.58337794        nan        nan\n",
      " 0.60402632 0.56993633 0.57914778 0.58127818 0.58269524 0.58195602\n",
      " 0.58195602 0.58195602        nan        nan 0.60402632 0.56993633\n",
      " 0.57914778 0.58127818 0.58269524 0.58195602 0.58195602 0.58195602\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58127818\n",
      " 0.58269524 0.58189267 0.58189267 0.58189267        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58248883 0.58269524 0.58256652\n",
      " 0.58256652 0.58256652]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"glm_l1_select\"] = model_tuner(LogisticRegression(penalty=\"l1\", solver=\"saga\", max_iter=10000),preprocessor_select(),param_grids[\"params_glm_l1_select\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"glm_l1_PCA\"] = model_tuner(LogisticRegression(penalty=\"l1\", solver=\"saga\", max_iter=10000),preprocessor_PCA(),param_grids[\"params_glm_l1_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "1400 fits failed out of a total of 7000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by LogisticRegression.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1247, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by LogisticRegression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.59616765 0.57331892 0.58345906 0.58626953\n",
      " 0.5827065  0.58948642 0.58896894 0.59234529        nan        nan\n",
      " 0.54767813 0.55329287 0.55329287 0.55329287 0.56161216 0.56532615\n",
      " 0.56532615 0.56532615        nan        nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.60535292 0.58109303 0.58360466 0.58796748 0.58805457 0.58520712\n",
      " 0.58533283 0.58529673        nan        nan 0.60524345 0.60993785\n",
      " 0.6058519  0.60541709 0.59555272 0.60290162 0.6043353  0.6043353\n",
      "        nan        nan 0.61012723 0.60828057 0.61078662 0.6082394\n",
      " 0.60832193 0.61023519 0.61023519 0.61023519        nan        nan\n",
      " 0.60711298 0.60698793 0.60698793 0.60698793 0.60889378 0.60946901\n",
      " 0.60946901 0.60946901        nan        nan 0.54602712 0.54663762\n",
      " 0.54663762 0.54663762 0.54792327 0.54754812 0.54754812 0.54754812\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.60485898 0.57323408\n",
      " 0.58274364 0.585191   0.58876877 0.58965141 0.58969049 0.59026191\n",
      "        nan        nan 0.60479879 0.57689001 0.58435277 0.58496671\n",
      " 0.58158557 0.57739643 0.57800693 0.57864469        nan        nan\n",
      " 0.60419714 0.58845358 0.58715549 0.58843971 0.58583357 0.58800074\n",
      " 0.58800074 0.58800074        nan        nan 0.60580228 0.60848537\n",
      " 0.60936452 0.60933946 0.6104565  0.61055008 0.61055008 0.61055008\n",
      "        nan        nan 0.6058648  0.6164644  0.61376069 0.61436602\n",
      " 0.61449853 0.614436   0.614436   0.614436          nan        nan\n",
      " 0.6063454  0.60632537 0.60528186 0.60562509 0.60598214 0.60604467\n",
      " 0.60604467 0.60604467        nan        nan 0.60784838 0.61228705\n",
      " 0.612382   0.61298733 0.61168172 0.61168172 0.61168172 0.61168172\n",
      "        nan        nan 0.60972395 0.60964183 0.60964183 0.60964183\n",
      " 0.60964183 0.61034211 0.61034211 0.61034211        nan        nan\n",
      " 0.61148075 0.61148075 0.61148075 0.61148075 0.61148075 0.61148075\n",
      " 0.61148075 0.61148075        nan        nan 0.61047248 0.61047248\n",
      " 0.61047248 0.61047248 0.61047248 0.61047248 0.61047248 0.61047248\n",
      "        nan        nan 0.60543421 0.57197241 0.58192313 0.5803555\n",
      " 0.58309652 0.58233647 0.58233647 0.58233647        nan        nan\n",
      " 0.60670592 0.57306189 0.58658061 0.58591411 0.58822082 0.58688278\n",
      " 0.58688278 0.58688278        nan        nan 0.60613449 0.57622832\n",
      " 0.58664518 0.59181897 0.58537976 0.58674505 0.58674505 0.58674505\n",
      "        nan        nan 0.60613449 0.57672074 0.58803949 0.58419921\n",
      " 0.58315162 0.58535474 0.58535474 0.58535474        nan        nan\n",
      " 0.60613449 0.57693198 0.57999131 0.58213411 0.57950241 0.57867328\n",
      " 0.57867328 0.57867328        nan        nan 0.60677225 0.57778695\n",
      " 0.58046098 0.58119735 0.58114596 0.57909798 0.57909798 0.57909798\n",
      "        nan        nan 0.60684077 0.58035233 0.57899767 0.57839234\n",
      " 0.5783174  0.57901768 0.57901768 0.57901768        nan        nan\n",
      " 0.60540045 0.59107434 0.58759872 0.58699339 0.58751618 0.58617815\n",
      " 0.58617815 0.58617815        nan        nan 0.6047627  0.59632299\n",
      " 0.5923438  0.5923438  0.59100577 0.59100577 0.59100577 0.59100577\n",
      "        nan        nan 0.60419347 0.59759299 0.59894858 0.59894858\n",
      " 0.5982483  0.5982483  0.5982483  0.5982483         nan        nan\n",
      " 0.60463164 0.56991288 0.5792051  0.57835959 0.5849534  0.58202274\n",
      " 0.58138498 0.58138498        nan        nan 0.60543421 0.5726426\n",
      " 0.58192597 0.58087215 0.58046614 0.58046614 0.58046614 0.58046614\n",
      "        nan        nan 0.60543421 0.57390323 0.58331766 0.58195818\n",
      " 0.58137998 0.58336461 0.58336461 0.58336461        nan        nan\n",
      " 0.60543421 0.57447846 0.58543839 0.58205824 0.58203771 0.58139996\n",
      " 0.58139996 0.58139996        nan        nan 0.60543421 0.57723108\n",
      " 0.58490526 0.58529576 0.58669334 0.58669334 0.58669334 0.58669334\n",
      "        nan        nan 0.60543421 0.57657563 0.58814536 0.58719415\n",
      " 0.58732003 0.58661975 0.58661975 0.58661975        nan        nan\n",
      " 0.60552916 0.57566276 0.58471681 0.58577654 0.58731548 0.5866152\n",
      " 0.5866152  0.5866152         nan        nan 0.60552916 0.57492638\n",
      " 0.58340603 0.5850797  0.58668498 0.58668498 0.58668498 0.58668498\n",
      "        nan        nan 0.60620302 0.57632104 0.58667359 0.58667359\n",
      " 0.58727891 0.58727891 0.58727891 0.58727891        nan        nan\n",
      " 0.60620302 0.57850796 0.58329094 0.58258182 0.5839287  0.58329094\n",
      " 0.58329094 0.58329094        nan        nan 0.60463164 0.57057409\n",
      " 0.57980309 0.58817302 0.58452204 0.5826811  0.5826811  0.5826811\n",
      "        nan        nan 0.60463164 0.57057409 0.5784475  0.58882086\n",
      " 0.58523094 0.58385039 0.58385039 0.58385039        nan        nan\n",
      " 0.60463164 0.57057409 0.57857621 0.58761168 0.58400362 0.58259926\n",
      " 0.58259926 0.58259926        nan        nan 0.60402632 0.57057409\n",
      " 0.5786785  0.58680911 0.58274421 0.58274421 0.58274421 0.58274421\n",
      "        nan        nan 0.60402632 0.57117941 0.58064162 0.58577961\n",
      " 0.58208014 0.58144239 0.58144239 0.58144239        nan        nan\n",
      " 0.60402632 0.57183472 0.58125212 0.5841671  0.58387344 0.58387344\n",
      " 0.58387344 0.58387344        nan        nan 0.60402632 0.57312779\n",
      " 0.58120214 0.58278655 0.5834882  0.5834882  0.5834882  0.5834882\n",
      "        nan        nan 0.60402632 0.57312779 0.58193851 0.58144851\n",
      " 0.58141461 0.58202511 0.58202511 0.58202511        nan        nan\n",
      " 0.60470017 0.57441214 0.58202757 0.58221732 0.58198101 0.58259151\n",
      " 0.58259151 0.58259151        nan        nan 0.60470017 0.57502264\n",
      " 0.58200985 0.58066815 0.58009672 0.58066815 0.58066815 0.58066815\n",
      "        nan        nan 0.60402632 0.57057409 0.57914778 0.58549234\n",
      " 0.58524243 0.58591248 0.58591248 0.58591248        nan        nan\n",
      " 0.60402632 0.57057409 0.57914778 0.58488184 0.58581386 0.58524243\n",
      " 0.58597881 0.58524243        nan        nan 0.60402632 0.57057409\n",
      " 0.57849247 0.58470081 0.58581386 0.58524243 0.58524243 0.58524243\n",
      "        nan        nan 0.60402632 0.57057409 0.57779219 0.58422653\n",
      " 0.58380197 0.5839044  0.5839044  0.5839044         nan        nan\n",
      " 0.60402632 0.57057409 0.57779219 0.58422653 0.58246394 0.58265614\n",
      " 0.58265614 0.58265614        nan        nan 0.60402632 0.57057409\n",
      " 0.57779219 0.58332026 0.58185344 0.58201839 0.58201839 0.58201839\n",
      "        nan        nan 0.60402632 0.57057409 0.57779219 0.5826825\n",
      " 0.58320903 0.5826376  0.5826376  0.5826376         nan        nan\n",
      " 0.60402632 0.57057409 0.57792091 0.58325393 0.58327155 0.58270012\n",
      " 0.58270012 0.58270012        nan        nan 0.60402632 0.57057409\n",
      " 0.57792091 0.58392251 0.58327535 0.58327535 0.58327535 0.58327535\n",
      "        nan        nan 0.60470017 0.57057409 0.57872347 0.58392251\n",
      " 0.58319147 0.58319147 0.58319147 0.58319147        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58454324 0.5834139  0.58331161\n",
      " 0.58331161 0.58331161        nan        nan 0.60402632 0.56993633\n",
      " 0.57914778 0.58454324 0.5834139  0.58394937 0.58394937 0.58394937\n",
      "        nan        nan 0.60402632 0.56993633 0.57914778 0.58406896\n",
      " 0.5834139  0.58394937 0.58394937 0.58394937        nan        nan\n",
      " 0.60402632 0.56993633 0.57914778 0.58406896 0.5834139  0.58458712\n",
      " 0.58458712 0.58458712        nan        nan 0.60402632 0.56993633\n",
      " 0.57914778 0.58454324 0.5834139  0.58458712 0.58458712 0.58458712\n",
      "        nan        nan 0.60402632 0.56993633 0.57849247 0.58454324\n",
      " 0.5834139  0.58458712 0.58458712 0.58458712        nan        nan\n",
      " 0.60402632 0.56993633 0.57849247 0.58406896 0.5834139  0.58401569\n",
      " 0.58401569 0.58401569        nan        nan 0.60402632 0.56993633\n",
      " 0.57849247 0.58384296 0.5834139  0.58401569 0.58401569 0.58401569\n",
      "        nan        nan 0.60402632 0.56993633 0.57849247 0.58336868\n",
      " 0.5834139  0.58337794 0.58337794 0.58337794        nan        nan\n",
      " 0.60402632 0.56993633 0.57849247 0.58271337 0.58405165 0.58337794\n",
      " 0.58337794 0.58337794        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58127818 0.58336909 0.58195602 0.58195602 0.58195602\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58127818\n",
      " 0.58336909 0.58195602 0.58195602 0.58195602        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58248883 0.58336909 0.58195602\n",
      " 0.58195602 0.58195602        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58248883 0.58269524 0.58195602 0.58195602 0.58195602\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58248883\n",
      " 0.58269524 0.58195602 0.58195602 0.58195602        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58248883 0.58269524 0.58195602\n",
      " 0.58195602 0.58195602        nan        nan 0.60402632 0.56993633\n",
      " 0.57914778 0.58127818 0.58269524 0.58195602 0.58195602 0.58195602\n",
      "        nan        nan 0.60402632 0.56993633 0.57914778 0.58248883\n",
      " 0.58269524 0.58195602 0.58195602 0.58195602        nan        nan\n",
      " 0.60402632 0.56993633 0.57914778 0.58248883 0.58269524 0.58195602\n",
      " 0.58195602 0.58195602        nan        nan 0.60402632 0.56993633\n",
      " 0.57914778 0.58127818 0.58269524 0.58195602 0.58195602 0.58195602\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58127818\n",
      " 0.58269524 0.58256652 0.58256652 0.58256652        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58248883 0.58269524 0.58256652\n",
      " 0.58256652 0.58256652        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58127818 0.58269524 0.58256652 0.58256652 0.58256652\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58127818\n",
      " 0.58269524 0.58256652 0.58256652 0.58256652        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58127818 0.58269524 0.58256652\n",
      " 0.58256652 0.58256652        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58127818 0.58269524 0.58256652 0.58256652 0.58256652\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58248883\n",
      " 0.58269524 0.58256652 0.58256652 0.58256652        nan        nan\n",
      " 0.60402632 0.56993633 0.57980309 0.58127818 0.58269524 0.58256652\n",
      " 0.58256652 0.58256652        nan        nan 0.60402632 0.56993633\n",
      " 0.57980309 0.58248883 0.58269524 0.58256652 0.58256652 0.58256652\n",
      "        nan        nan 0.60402632 0.56993633 0.57980309 0.58248883\n",
      " 0.58269524 0.58256652 0.58256652 0.58256652]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"glm_en_select\"] = model_tuner(LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", max_iter=10000),preprocessor_select(),param_grids[\"params_glm_en_select\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"glm_en_PCA\"] = model_tuner(LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", max_iter=10000),preprocessor_PCA(),param_grids[\"params_glm_en_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "1120 fits failed out of a total of 5600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 197, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by SVC.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "800 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 197, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by SVC.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.54483408 0.5808386  0.58197251 0.59134729\n",
      " 0.59182488 0.59835704 0.60168601 0.60104825        nan        nan\n",
      " 0.53382741 0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.54483408 0.5808386  0.58197251 0.58866389 0.59182488 0.59835704\n",
      " 0.60168601 0.60104825        nan        nan 0.53382741 0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.6091211  0.58754558\n",
      " 0.58623013 0.58931496 0.58950632 0.59120253 0.59316349 0.59316349\n",
      "        nan        nan 0.55063591 0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.58812736 0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.6091211  0.58754558 0.58623013 0.58931496\n",
      " 0.58950632 0.59120253 0.59316349 0.59316349        nan        nan\n",
      " 0.55063591 0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.58812736 0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.60883196 0.57873451 0.59179193 0.59387841 0.59466714 0.591456\n",
      " 0.59287998 0.59351773        nan        nan 0.57281585 0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.60856949 0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.60966257 0.51974847 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.60883196 0.57873451\n",
      " 0.59179193 0.59387841 0.59466714 0.591456   0.59287998 0.59351773\n",
      "        nan        nan 0.57281585 0.5        0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.60856949 0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.60966257 0.51974847\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.60638129 0.5748464  0.58713047 0.58699186\n",
      " 0.58795743 0.58650027 0.5846853  0.5852958         nan        nan\n",
      " 0.56817686 0.50239022 0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan 0.60545448 0.53124511\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.57861292 0.58357323 0.57402793 0.55957215\n",
      " 0.58128107 0.58965771 0.59285614 0.59489445        nan        nan\n",
      " 0.60638129 0.5748464  0.58713047 0.58699186 0.58795743 0.58650027\n",
      " 0.5846853  0.5852958         nan        nan 0.56817686 0.50239022\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      "        nan        nan 0.60545448 0.53124511 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5               nan        nan\n",
      " 0.57861292 0.58357323 0.57402793 0.56286088 0.58128107 0.58965771\n",
      " 0.59285614 0.59489445        nan        nan 0.60695272 0.57884527\n",
      " 0.5865691  0.58837683 0.59127689 0.58162228 0.58165487 0.58488776\n",
      "        nan        nan 0.57115528 0.57092072 0.5        0.5\n",
      " 0.50131062 0.50196592 0.50196592 0.50196592        nan        nan\n",
      " 0.60573211 0.59480461 0.59350854 0.58656258 0.60127919 0.61200005\n",
      " 0.60922575 0.61056379        nan        nan 0.52808473 0.5822755\n",
      " 0.58090698 0.58806327 0.59043851 0.59325451 0.59599432 0.5966946\n",
      "        nan        nan 0.60695272 0.57884527 0.5865691  0.58837683\n",
      " 0.59127689 0.58162228 0.58165487 0.58488776        nan        nan\n",
      " 0.57115528 0.57092072 0.5        0.5        0.50131062 0.50196592\n",
      " 0.50196592 0.50196592        nan        nan 0.60573211 0.59480461\n",
      " 0.59350854 0.58656258 0.60127919 0.61200005 0.60922575 0.61056379\n",
      "        nan        nan 0.52808473 0.5822755  0.58090698 0.58806327\n",
      " 0.59043851 0.59325451 0.59599432 0.5966946         nan        nan\n",
      " 0.60631497 0.57875054 0.5858272  0.5782825  0.56818892 0.56745714\n",
      " 0.56626338 0.56574747        nan        nan 0.5740331  0.58186131\n",
      " 0.58080585 0.58329547 0.60567627 0.62015198 0.62260247 0.6210135\n",
      "        nan        nan 0.60307985 0.60658786 0.60156425 0.60104253\n",
      " 0.61989385 0.63604347 0.6350942  0.63775186        nan        nan\n",
      " 0.52430163 0.58184911 0.59022342 0.59382217 0.58637512 0.58848527\n",
      " 0.58357846 0.58568814        nan        nan 0.60631497 0.57875054\n",
      " 0.58920355 0.5766787  0.56818892 0.56745714 0.56626338 0.56574747\n",
      "        nan        nan 0.5740331  0.58186131 0.58080585 0.58329547\n",
      " 0.60567627 0.62015198 0.62260247 0.6210135         nan        nan\n",
      " 0.60307985 0.60658786 0.60156425 0.60104253 0.61989385 0.63604347\n",
      " 0.6350942  0.63775186        nan        nan 0.52430163 0.58184911\n",
      " 0.59022342 0.59382217 0.58637512 0.58848527 0.58357846 0.58568814\n",
      "        nan        nan 0.60574354 0.5642628  0.52474173 0.52304502\n",
      " 0.50863366 0.53055068 0.53912689 0.53219309        nan        nan\n",
      " 0.57183477 0.5656869  0.59043969 0.59423851 0.62182903 0.63052616\n",
      " 0.62692264 0.62667088        nan        nan 0.60325121 0.59815867\n",
      " 0.62520038 0.62967198 0.67708755 0.68053036 0.68531101 0.68665788\n",
      "        nan        nan 0.52376616 0.57081537 0.57367092 0.5712423\n",
      " 0.57674985 0.57855247 0.56868198 0.57041652        nan        nan\n",
      " 0.60574354 0.5642628  0.52474173 0.51944426 0.50863366 0.53055068\n",
      " 0.53912689 0.53219309        nan        nan 0.57183477 0.5656869\n",
      " 0.59369099 0.59423851 0.62182903 0.63052616 0.62692264 0.62667088\n",
      "        nan        nan 0.60325121 0.59815867 0.62520038 0.62967198\n",
      " 0.67708755 0.68053036 0.68531101 0.68665788        nan        nan\n",
      " 0.52376616 0.57081537 0.57367092 0.5712423  0.57674985 0.57855247\n",
      " 0.56868198 0.57041652        nan        nan 0.61000124 0.49495022\n",
      " 0.51439575 0.52407555 0.499955   0.53553321 0.50850533 0.49949209\n",
      "        nan        nan 0.51763028 0.54878785 0.58388586 0.59411452\n",
      " 0.62810971 0.63365877 0.62971367 0.6295878         nan        nan\n",
      " 0.60147719 0.59045815 0.62210262 0.62312749 0.67741684 0.68150499\n",
      " 0.68408155 0.68539233        nan        nan 0.52369983 0.55788575\n",
      " 0.57129412 0.5591294  0.54759586 0.54799938 0.55078112 0.54198308\n",
      "        nan        nan 0.61000124 0.49495022 0.51439575 0.52754526\n",
      " 0.499955   0.53553321 0.50850533 0.49949209        nan        nan\n",
      " 0.51414138 0.54878785 0.58388586 0.59411452 0.62810971 0.63365877\n",
      " 0.62971367 0.6295878         nan        nan 0.60147719 0.59045815\n",
      " 0.62210262 0.62312749 0.67741684 0.68150499 0.68408155 0.68539233\n",
      "        nan        nan 0.52369983 0.55788575 0.57129412 0.55818084\n",
      " 0.54759586 0.54799938 0.55078112 0.54198308        nan        nan\n",
      " 0.56383915 0.49403911 0.51439575 0.52407555 0.499955   0.53553321\n",
      " 0.50850533 0.49949209        nan        nan 0.56033463 0.54323483\n",
      " 0.58388586 0.59411452 0.62810971 0.63365877 0.62971367 0.6295878\n",
      "        nan        nan 0.60318795 0.58107189 0.62210262 0.62178578\n",
      " 0.67741684 0.68150499 0.68408155 0.68539233        nan        nan\n",
      " 0.52369983 0.55517459 0.55062396 0.55885533 0.53411635 0.5265059\n",
      " 0.5337492  0.52539706        nan        nan 0.56383915 0.49403911\n",
      " 0.51439575 0.52754526 0.499955   0.53553321 0.50850533 0.49949209\n",
      "        nan        nan 0.55934673 0.54323483 0.58388586 0.59130007\n",
      " 0.62810971 0.63365877 0.62971367 0.6295878         nan        nan\n",
      " 0.60318795 0.58107189 0.62210262 0.62312749 0.67741684 0.68150499\n",
      " 0.68408155 0.68539233        nan        nan 0.52369983 0.55517459\n",
      " 0.55062396 0.55885533 0.53411635 0.5265059  0.5337492  0.52539706\n",
      "        nan        nan 0.5725295  0.50034388 0.51439575 0.52407555\n",
      " 0.499955   0.53553321 0.50850533 0.49949209        nan        nan\n",
      " 0.5214267  0.54050381 0.58388586 0.59411452 0.62810971 0.63365877\n",
      " 0.62971367 0.6295878         nan        nan 0.60392829 0.58043513\n",
      " 0.62210262 0.62178578 0.67741684 0.68150499 0.68408155 0.68539233\n",
      "        nan        nan 0.52369983 0.54811019 0.55379339 0.55662745\n",
      " 0.52722762 0.5052953  0.5186071  0.51689556        nan        nan\n",
      " 0.5725295  0.50034388 0.51439575 0.52407555 0.499955   0.53553321\n",
      " 0.50850533 0.49949209        nan        nan 0.5214267  0.54050381\n",
      " 0.58388586 0.59411452 0.62810971 0.63365877 0.62971367 0.6295878\n",
      "        nan        nan 0.60392829 0.58043513 0.62210262 0.62178578\n",
      " 0.67741684 0.68150499 0.68408155 0.68539233        nan        nan\n",
      " 0.52369983 0.54811019 0.55379339 0.55662745 0.52722762 0.5052953\n",
      " 0.5186071  0.51689556]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"svm_select\"] = model_tuner(SVC(probability=True, max_iter=10000),preprocessor_select(),param_grids[\"params_svm_select\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"svm_PCA\"] = model_tuner(SVC(probability=True, max_iter=10000),preprocessor_PCA(),param_grids[\"params_svm_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "14 fits failed out of a total of 70.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 660, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by LinearDiscriminantAnalysis.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 660, in fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by LinearDiscriminantAnalysis.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.60402632 0.5731816  0.58059194 0.58537936\n",
      " 0.58622455 0.58462308 0.58462308 0.58462308]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"lda_select\"] = model_tuner(LinearDiscriminantAnalysis(),preprocessor_select(),param_grids[\"params_lda_select\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"lda_PCA\"] = model_tuner(LinearDiscriminantAnalysis(),preprocessor_PCA(),param_grids[\"params_lda_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "84 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 986, in fit\n",
      "    X, y = validate_data(self, X, y)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by QuadraticDiscriminantAnalysis.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 986, in fit\n",
      "    X, y = validate_data(self, X, y)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by QuadraticDiscriminantAnalysis.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.60276522 0.58987488 0.57035585 0.57570607\n",
      " 0.56436403 0.57260093 0.57074347 0.56937818        nan        nan\n",
      " 0.60138096 0.59393884 0.57251117 0.58956668 0.57519615 0.58504257\n",
      " 0.58019043 0.57894218        nan        nan 0.60504755 0.5952388\n",
      " 0.57533744 0.59678652 0.5774426  0.58594773 0.58380517 0.58306879\n",
      "        nan        nan 0.60687174 0.59570703 0.57638258 0.59549346\n",
      " 0.58155833 0.58653823 0.58803345 0.5886712         nan        nan\n",
      " 0.60707378 0.59626156 0.58059681 0.59889025 0.59423672 0.59832423\n",
      " 0.59650526 0.59650526        nan        nan 0.60922672 0.59301539\n",
      " 0.59725374 0.5971603  0.62773345 0.63428413 0.63652923 0.63579285]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"qda_select\"] = model_tuner(QuadraticDiscriminantAnalysis(),preprocessor_select(),param_grids[\"params_qda_select\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"qda_PCA\"] = model_tuner(QuadraticDiscriminantAnalysis(),preprocessor_PCA(),param_grids[\"params_qda_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "448 fits failed out of a total of 2240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "128 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 239, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 478, in _fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1285, 0)) while a minimum of 1 is required by KNeighborsClassifier.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 239, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 478, in _fit\n",
      "    X, y = validate_data(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1137, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Found array with 0 feature(s) (shape=(1286, 0)) while a minimum of 1 is required by KNeighborsClassifier.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\untitled\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.53213785 0.57243292 0.56967822 0.58676432\n",
      " 0.64744171 0.66134613 0.65981741 0.66001548        nan        nan\n",
      " 0.52754534 0.57243292 0.56967822 0.58676432 0.64744171 0.66134613\n",
      " 0.65981741 0.66001548        nan        nan 0.55562493 0.56083036\n",
      " 0.59951824 0.59970997 0.65386702 0.65803999 0.67067902 0.67226963\n",
      "        nan        nan 0.5353287  0.56487602 0.5937216  0.61268435\n",
      " 0.66008516 0.67801657 0.67748234 0.68252952        nan        nan\n",
      " 0.56645147 0.58126778 0.60573191 0.60812273 0.65579657 0.67274586\n",
      " 0.66575558 0.66770411        nan        nan 0.53439463 0.58654336\n",
      " 0.60666994 0.61065899 0.66516549 0.67179334 0.68014805 0.68380387\n",
      "        nan        nan 0.59793108 0.59064856 0.59898765 0.60266653\n",
      " 0.6642759  0.68459066 0.68259117 0.68444957        nan        nan\n",
      " 0.54903736 0.59375385 0.59910528 0.60852875 0.66956188 0.68221566\n",
      " 0.68159296 0.68527319        nan        nan 0.603855   0.58663317\n",
      " 0.60426769 0.59513895 0.65388764 0.66741943 0.66090501 0.66912172\n",
      "        nan        nan 0.55278167 0.59222867 0.60982774 0.59472407\n",
      " 0.65773397 0.67465622 0.66415297 0.67468581        nan        nan\n",
      " 0.60271792 0.59575473 0.58929139 0.59666838 0.63300215 0.65649132\n",
      " 0.65483981 0.65833246        nan        nan 0.55293122 0.59221\n",
      " 0.59819649 0.60192414 0.63963711 0.66974255 0.66494289 0.66796861\n",
      "        nan        nan 0.60223275 0.596766   0.57426877 0.59408409\n",
      " 0.61636721 0.63749612 0.63609634 0.64059517        nan        nan\n",
      " 0.55448818 0.59722554 0.57930342 0.59295111 0.62501026 0.64458275\n",
      " 0.64842235 0.64968829        nan        nan 0.60672256 0.59246054\n",
      " 0.57936165 0.59683209 0.62079042 0.63158067 0.63138651 0.63672908\n",
      "        nan        nan 0.55505975 0.59487306 0.58935591 0.5865144\n",
      " 0.63344348 0.64027289 0.637947   0.64246341        nan        nan\n",
      " 0.52900982 0.54461596 0.59451539 0.60432559 0.6905676  0.7352398\n",
      " 0.73614266 0.74013836        nan        nan 0.52277727 0.54461596\n",
      " 0.59451539 0.60358922 0.6905676  0.7352398  0.73614266 0.74013836\n",
      "        nan        nan 0.56487179 0.55113477 0.59316631 0.61884319\n",
      " 0.71060665 0.74812678 0.74465671 0.74698205        nan        nan\n",
      " 0.52615545 0.55161357 0.60871518 0.62917151 0.72079443 0.76701863\n",
      " 0.76661011 0.77075811        nan        nan 0.56773505 0.55943459\n",
      " 0.61314052 0.61787835 0.71918787 0.74960063 0.74922793 0.7512575\n",
      "        nan        nan 0.53530456 0.57567568 0.60936178 0.62541716\n",
      " 0.72408827 0.7688533  0.77305084 0.77666016        nan        nan\n",
      " 0.60248936 0.58180883 0.60031448 0.62129342 0.71314619 0.74106376\n",
      " 0.73401169 0.73820545        nan        nan 0.54923375 0.5872979\n",
      " 0.60489976 0.6387476  0.71760141 0.75114726 0.74546617 0.74787172\n",
      "        nan        nan 0.60741023 0.58496951 0.60157431 0.63934696\n",
      " 0.69674318 0.72637245 0.72390041 0.72352278        nan        nan\n",
      " 0.55368101 0.58934195 0.60828901 0.63795927 0.71484056 0.73443238\n",
      " 0.73660013 0.73343861        nan        nan 0.60400383 0.59702089\n",
      " 0.61158947 0.62098589 0.69367823 0.71617558 0.70957562 0.71220685\n",
      "        nan        nan 0.55471412 0.59949419 0.60689931 0.63162572\n",
      " 0.69996328 0.72300288 0.71921543 0.72181941        nan        nan\n",
      " 0.60338627 0.59464502 0.61689378 0.61610246 0.67046989 0.67550042\n",
      " 0.66843949 0.67300002        nan        nan 0.55412306 0.59874717\n",
      " 0.61836765 0.61415727 0.67527917 0.68455033 0.68314918 0.68423391\n",
      "        nan        nan 0.60649142 0.59605312 0.60878521 0.60828616\n",
      " 0.64571172 0.65892848 0.657024   0.65647602        nan        nan\n",
      " 0.55579026 0.59998937 0.60907834 0.6100295  0.6551316  0.66740584\n",
      " 0.66228291 0.66026218]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models[\"knn_select\"] = model_tuner(KNeighborsClassifier(),preprocessor_select(),param_grids[\"params_knn_select\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"knn_PCA\"] = model_tuner(KNeighborsClassifier(),preprocessor_PCA(),param_grids[\"params_knn_PCA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zapis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_basic_grids.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(models, \"all_basic_grids.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "untitled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
